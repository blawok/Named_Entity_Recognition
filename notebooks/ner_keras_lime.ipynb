{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner_keras_lime.ipynb",
      "provenance": [],
      "mount_file_id": "1-2xFnw2F3nHxxAiP4arMV3eQSMzljpPQ",
      "authorship_tag": "ABX9TyOa6WmPbpSqLgEFQRdEkGbh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blawok/Named_Entity_Recognition/blob/master/ner_keras_lime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oesQh63_bdwU",
        "colab_type": "text"
      },
      "source": [
        "Full run of example taken from https://www.depends-on-the-definition.com/interpretable-named-entity-recognition/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a53wl2gWfnL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeUOEBplbZY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "ab6b8d8c-d094-423e-c2de-23ea51816afd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NER/ner_dataset.csv\", encoding=\"latin1\").fillna(method=\"ffill\")\n",
        "data.tail(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1048565</th>\n",
              "      <td>Sentence: 47958</td>\n",
              "      <td>impact</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048566</th>\n",
              "      <td>Sentence: 47958</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048567</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>Indian</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048568</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>forces</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048569</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>said</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>they</td>\n",
              "      <td>PRP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>responded</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>attack</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Sentence #       Word  POS    Tag\n",
              "1048565  Sentence: 47958     impact   NN      O\n",
              "1048566  Sentence: 47958          .    .      O\n",
              "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
              "1048568  Sentence: 47959     forces  NNS      O\n",
              "1048569  Sentence: 47959       said  VBD      O\n",
              "1048570  Sentence: 47959       they  PRP      O\n",
              "1048571  Sentence: 47959  responded  VBD      O\n",
              "1048572  Sentence: 47959         to   TO      O\n",
              "1048573  Sentence: 47959        the   DT      O\n",
              "1048574  Sentence: 47959     attack   NN      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8BiMEQdboln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09a11c1d-82b0-4f00-c835-33e913522846"
      },
      "source": [
        "words = list(set(data[\"Word\"].values))\n",
        "n_words = len(words); n_words"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP7nDiFvbour",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1610897-b17d-4e20-81fe-ca5e3f1d3211"
      },
      "source": [
        "tags = list(set(data[\"Tag\"].values))\n",
        "n_tags = len(tags); n_tags"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLXcrhUhbo2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t--HX84Ebo-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(data)\n",
        "sentences = getter.sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0ron5db5Vh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c47f11f-0f6b-42bf-e222-8282b67ffc65"
      },
      "source": [
        "labels = [[s[2] for s in sent] for sent in sentences]\n",
        "sentences = [\" \".join([s[0] for s in sent]) for sent in sentences]\n",
        "sentences[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTQNjJ6Tb5dF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c1d27f1-f983-47fe-ac80-3fb3afe6874c"
      },
      "source": [
        "print(labels[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmMlaDEWb5ks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11c94ad5-def5-44aa-e3b8-62fa6debf372"
      },
      "source": [
        "from collections import Counter\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "word_cnt = Counter(data[\"Word\"].values)\n",
        "vocabulary = set(w[0] for w in word_cnt.most_common(5000))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1El2vZUb-v7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 50\n",
        "word2idx = {\"PAD\": 0, \"UNK\": 1}\n",
        "word2idx.update({w: i for i, w in enumerate(words) if w in vocabulary})\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXerczz7b-27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [[word2idx.get(w, word2idx[\"UNK\"]) for w in s.split()] for s in sentences]\n",
        "\n",
        "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
        "\n",
        "y = [[tag2idx[l_i] for l_i in l] for l in labels]\n",
        "\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45fk_oG_b-_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RxjRIgfcGdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, SpatialDropout1D, Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ec6nHNfcGj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_input = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=n_words, output_dim=50, input_length=max_len)(word_input)\n",
        "model = SpatialDropout1D(0.1)(model)\n",
        "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6RViajwcGrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(word_input, out)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlW-hziCcWEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "cf455995-836b-4209-bcea-84cf38b1eac1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 50, 50)            1758900   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 50, 200)           120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 50, 17)            3417      \n",
            "=================================================================\n",
            "Total params: 1,883,117\n",
            "Trainable params: 1,883,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH_yVHJNcM1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "fb157bd3-38b0-421c-e1b4-a7371a30bcb8"
      },
      "source": [
        "history = model.fit(X_tr, \n",
        "                    y_tr.reshape(*y_tr.shape, 1),\n",
        "                    batch_size=32,\n",
        "                    epochs=5,\n",
        "                    validation_split=0.1,\n",
        "                    verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 38846 samples, validate on 4317 samples\n",
            "Epoch 1/5\n",
            "38846/38846 [==============================] - 362s 9ms/step - loss: 0.1436 - accuracy: 0.9633 - val_loss: 0.0701 - val_accuracy: 0.9799\n",
            "Epoch 2/5\n",
            "38846/38846 [==============================] - 360s 9ms/step - loss: 0.0647 - accuracy: 0.9809 - val_loss: 0.0606 - val_accuracy: 0.9822\n",
            "Epoch 3/5\n",
            "38846/38846 [==============================] - 356s 9ms/step - loss: 0.0589 - accuracy: 0.9825 - val_loss: 0.0577 - val_accuracy: 0.9828\n",
            "Epoch 4/5\n",
            "38846/38846 [==============================] - 353s 9ms/step - loss: 0.0556 - accuracy: 0.9834 - val_loss: 0.0576 - val_accuracy: 0.9826\n",
            "Epoch 5/5\n",
            "38846/38846 [==============================] - 355s 9ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 0.0553 - val_accuracy: 0.9833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6qnBuypjTS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "05290f55-a4d4-4cd7-e0b0-0795312954ea"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\r\u001b[K     |███                             | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.4)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li9sqsIhcM8E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "dec74e2c-b1e3-48df-8bc9-37aa4cb10797"
      },
      "source": [
        "from eli5.lime import TextExplainer\n",
        "from eli5.lime.samplers import MaskingTextSampler"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No8lzePgcNDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NERExplainerGenerator(object):\n",
        "    \n",
        "    def __init__(self, model, word2idx, tag2idx, max_len):\n",
        "        self.model = model\n",
        "        self.word2idx = word2idx\n",
        "        self.tag2idx = tag2idx\n",
        "        self.idx2tag = {v: k for k,v in tag2idx.items()}\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def _preprocess(self, texts):\n",
        "        X = [[self.word2idx.get(w, self.word2idx[\"UNK\"]) for w in t.split()]\n",
        "             for t in texts]\n",
        "        X = pad_sequences(maxlen=self.max_len, sequences=X,\n",
        "                          padding=\"post\", value=self.word2idx[\"PAD\"])\n",
        "        return X\n",
        "    \n",
        "    def get_predict_function(self, word_index):\n",
        "        def predict_func(texts):\n",
        "            X = self._preprocess(texts)\n",
        "            p = self.model.predict(X)\n",
        "            return p[:,word_index,:]\n",
        "        return predict_func"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_etM08Icjfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "6db51f8b-5eee-4cf5-c49d-b8bfbfeafebb"
      },
      "source": [
        "index = 46781\n",
        "label = labels[index]\n",
        "text = sentences[index]\n",
        "print(text)\n",
        "print()\n",
        "print(\" \".join([f\"{t} ({l})\" for t, l in zip(text.split(), label)]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\n",
            "\n",
            "Nigeria (B-geo) 's (O) President (B-per) Olusegun (I-per) Obasanjo (I-per) expressed (O) his (O) condolences (O) , (O) noting (O) the (O) late (O) pontiff (O) promoted (O) religious (O) tolerance (O) and (O) democracy (O) in (O) the (O) West (O) African (B-gpe) nation (O) . (O)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvGAVimgcoMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "2a22e077-0929-429b-b179-10cf18d4cde8"
      },
      "source": [
        "for i, w in enumerate(text.split()):\n",
        "    print(f\"{i}: {w}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: Nigeria\n",
            "1: 's\n",
            "2: President\n",
            "3: Olusegun\n",
            "4: Obasanjo\n",
            "5: expressed\n",
            "6: his\n",
            "7: condolences\n",
            "8: ,\n",
            "9: noting\n",
            "10: the\n",
            "11: late\n",
            "12: pontiff\n",
            "13: promoted\n",
            "14: religious\n",
            "15: tolerance\n",
            "16: and\n",
            "17: democracy\n",
            "18: in\n",
            "19: the\n",
            "20: West\n",
            "21: African\n",
            "22: nation\n",
            "23: .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvmDrLgkcoUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "explainer_generator = NERExplainerGenerator(model, word2idx, tag2idx, max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgkGyRyDcob-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = 4\n",
        "predict_func = explainer_generator.get_predict_function(word_index=word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRjXtd1YcruS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampler = MaskingTextSampler(\n",
        "    replacement=\"UNK\",\n",
        "    max_replace=0.7,\n",
        "    token_pattern=None,\n",
        "    bow=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOWjJLi9cr3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "fa69b2ae-e1d9-4395-afb0-209c231b1fcd"
      },
      "source": [
        "samples, similarity = sampler.sample_near(text, n_samples=4)\n",
        "print(samples)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(\"UNK 's UNK UNK UNK UNK UNK UNK , noting the UNK pontiff promoted religious UNK UNK UNK UNK UNK West African UNK .\", \"Nigeria 'UNK President Olusegun Obasanjo expressed UNK condolences , noting UNK UNK UNK promoted UNK UNK UNK UNK in the UNK African nation .\", \"Nigeria 's President Olusegun UNK expressed his condolences , noting the late UNK promoted religious UNK and democracy UNK the West African nation .\", \"UNK 'UNK President Olusegun Obasanjo expressed UNK condolences , noting the late pontiff promoted UNK UNK UNK UNK in UNK West UNK nation .\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8iabboUcwuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "outputId": "1b58f56d-cef0-4c54-de25-78015b7facea"
      },
      "source": [
        "te = TextExplainer(\n",
        "    sampler=sampler,\n",
        "    position_dependent=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "te.fit(text, predict_func)\n",
        "\n",
        "te.explain_prediction(\n",
        "    target_names=list(explainer_generator.idx2tag.values()),\n",
        "    top_targets=3\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=I-per\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.964</b>, score <b>3.586</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.415\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.80%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.828\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 93.07%); opacity: 0.82\" title=\"-0.189\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(0, 100.00%, 82.99%); opacity: 0.86\" title=\"-0.683\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.43%); opacity: 1.00\" title=\"2.282\">President</span><span style=\"opacity: 0.80\"> Olusegun </span><span style=\"background-color: hsl(120, 100.00%, 68.71%); opacity: 0.94\" title=\"1.631\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.51%); opacity: 0.89\" title=\"1.083\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.31%); opacity: 0.83\" title=\"0.400\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.47%); opacity: 0.81\" title=\"-0.137\">condolences</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(120, 100.00%, 96.96%); opacity: 0.81\" title=\"0.058\">noting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.84%); opacity: 0.81\" title=\"0.062\">the</span><span style=\"opacity: 0.80\"> late pontiff </span><span style=\"background-color: hsl(120, 100.00%, 99.97%); opacity: 0.80\" title=\"0.000\">promoted</span><span style=\"opacity: 0.80\"> religious tolerance </span><span style=\"background-color: hsl(0, 100.00%, 97.45%); opacity: 0.80\" title=\"-0.045\">and</span><span style=\"opacity: 0.80\"> democracy </span><span style=\"background-color: hsl(120, 100.00%, 98.66%); opacity: 0.80\" title=\"0.018\">in</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 99.70%); opacity: 0.80\" title=\"0.002\">West</span><span style=\"opacity: 0.80\"> African </span><span style=\"background-color: hsl(0, 100.00%, 96.66%); opacity: 0.81\" title=\"-0.067\">nation</span><span style=\"opacity: 0.80\"> .</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=I-org\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.009</b>, score <b>-4.706</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.75%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.838\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 81.77%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -3.869\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 94.70%); opacity: 0.81\" title=\"-0.129\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(120, 100.00%, 90.48%); opacity: 0.83\" title=\"0.298\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.317\">President</span><span style=\"opacity: 0.80\"> Olusegun </span><span style=\"background-color: hsl(0, 100.00%, 80.45%); opacity: 0.87\" title=\"-0.833\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.67%); opacity: 0.83\" title=\"-0.335\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.07%); opacity: 0.83\" title=\"-0.363\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.48%); opacity: 0.80\" title=\"-0.045\">condolences</span><span style=\"opacity: 0.80\"> , noting the late pontiff promoted </span><span style=\"background-color: hsl(120, 100.00%, 99.53%); opacity: 0.80\" title=\"0.004\">religious</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.32%); opacity: 0.80\" title=\"0.025\">tolerance</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.34%); opacity: 0.80\" title=\"-0.048\">and</span><span style=\"opacity: 0.80\"> democracy </span><span style=\"background-color: hsl(0, 100.00%, 96.11%); opacity: 0.81\" title=\"-0.083\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.55%); opacity: 0.80\" title=\"-0.043\">the</span><span style=\"opacity: 0.80\"> West African nation .</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=B-per\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.009</b>, score <b>-4.744</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.80%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.180\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.33%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -2.564\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"opacity: 0.80\">Nigeria &#x27;</span><span style=\"background-color: hsl(120, 100.00%, 92.60%); opacity: 0.82\" title=\"0.208\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.16%); opacity: 0.92\" title=\"-1.381\">President</span><span style=\"opacity: 0.80\"> Olusegun </span><span style=\"background-color: hsl(120, 100.00%, 96.20%); opacity: 0.81\" title=\"0.080\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.47%); opacity: 0.87\" title=\"-0.772\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.55%); opacity: 0.81\" title=\"0.070\">his</span><span style=\"opacity: 0.80\"> condolences , </span><span style=\"background-color: hsl(0, 100.00%, 93.06%); opacity: 0.82\" title=\"-0.190\">noting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.39%); opacity: 0.81\" title=\"-0.106\">the</span><span style=\"opacity: 0.80\"> late pontiff </span><span style=\"background-color: hsl(0, 100.00%, 98.23%); opacity: 0.80\" title=\"-0.027\">promoted</span><span style=\"opacity: 0.80\"> religious tolerance and democracy in the West </span><span style=\"background-color: hsl(0, 100.00%, 96.81%); opacity: 0.81\" title=\"-0.063\">African</span><span style=\"opacity: 0.80\"> nation .</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "Explanation(estimator=\"SGDClassifier(alpha=0.001, average=False, class_weight=None,\\n              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\\n              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\\n              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\\n              power_t=0.5, random_state=RandomState(MT19937) at 0x7F4EE59C6EB8,\\n              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\\n              warm_start=False)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='I-per', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[2] President', weight=2.2817379198818903, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=1.631309184495366, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=1.083247562899191, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=0.39951762401070257, std=None, value=1.0), FeatureWeight(feature='[9] the', weight=0.06156431906023214, std=None, value=1.0), FeatureWeight(feature='[8] noting', weight=0.0582290107021964, std=None, value=1.0), FeatureWeight(feature='[17] in', weight=0.018185977484624725, std=None, value=1.0), FeatureWeight(feature='[19] West', weight=0.002164615238736828, std=None, value=1.0), FeatureWeight(feature='[12] promoted', weight=6.545568471281508e-05, std=None, value=1.0)], neg=[FeatureWeight(feature='<BIAS>', weight=-0.8283741369664093, std=None, value=1.0), FeatureWeight(feature='[1] s', weight=-0.6829643540293584, std=None, value=1.0), FeatureWeight(feature='[0] Nigeria', weight=-0.18916522066056898, std=None, value=1.0), FeatureWeight(feature='[7] condolences', weight=-0.13700070534388395, std=None, value=1.0), FeatureWeight(feature='[21] nation', weight=-0.06687247201345795, std=None, value=1.0), FeatureWeight(feature='[15] and', weight=-0.04545125096184615, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.963595419649382, score=3.586193529482129, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], -0.18916522066056898), ('s', [(9, 10)], -0.6829643540293584), ('President', [(11, 20)], 2.2817379198818903), ('Obasanjo', [(30, 38)], 1.631309184495366), ('expressed', [(39, 48)], 1.083247562899191), ('his', [(49, 52)], 0.39951762401070257), ('condolences', [(53, 64)], -0.13700070534388395), ('noting', [(67, 73)], 0.0582290107021964), ('the', [(74, 77)], 0.06156431906023214), ('promoted', [(91, 99)], 6.545568471281508e-05), ('and', [(120, 123)], -0.04545125096184615), ('in', [(134, 136)], 0.018185977484624725), ('West', [(141, 145)], 0.002164615238736828), ('nation', [(154, 160)], -0.06687247201345795)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=4.414567666448538, std=None, value=None)], neg=[FeatureWeight(feature='<BIAS>', weight=-0.8283741369664093, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='I-org', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[1] s', weight=0.2980481147624961, std=None, value=1.0), FeatureWeight(feature='[14] tolerance', weight=0.0249157386807236, std=None, value=1.0), FeatureWeight(feature='[13] religious', weight=0.0040806361803185955, std=None, value=1.0)], neg=[FeatureWeight(feature='[2] President', weight=-2.3168411448017427, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-0.837555955060667, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=-0.8331010437185977, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=-0.3630006868274711, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=-0.33506984757923663, std=None, value=1.0), FeatureWeight(feature='[0] Nigeria', weight=-0.12911742258467399, std=None, value=1.0), FeatureWeight(feature='[17] in', weight=-0.08291292550308389, std=None, value=1.0), FeatureWeight(feature='[15] and', weight=-0.04829720526456041, std=None, value=1.0), FeatureWeight(feature='[7] condolences', weight=-0.044536990352882895, std=None, value=1.0), FeatureWeight(feature='[18] the', weight=-0.04286929352279637, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.00887059913641454, score=-4.706258025592175, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], -0.12911742258467399), ('s', [(9, 10)], 0.2980481147624961), ('President', [(11, 20)], -2.3168411448017427), ('Obasanjo', [(30, 38)], -0.8331010437185977), ('expressed', [(39, 48)], -0.33506984757923663), ('his', [(49, 52)], -0.3630006868274711), ('condolences', [(53, 64)], -0.044536990352882895), ('religious', [(100, 109)], 0.0040806361803185955), ('tolerance', [(110, 119)], 0.0249157386807236), ('and', [(120, 123)], -0.04829720526456041), ('in', [(134, 136)], -0.08291292550308389), ('the', [(137, 140)], -0.04286929352279637)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-3.8687020705315063, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=-0.837555955060667, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='B-per', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[1] s', weight=0.20787264732896882, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=0.08014286981955294, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=0.0698215184496014, std=None, value=1.0)], neg=[FeatureWeight(feature='<BIAS>', weight=-2.564497181205572, std=None, value=1.0), FeatureWeight(feature='[2] President', weight=-1.380863149361317, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=-0.7717426962334071, std=None, value=1.0), FeatureWeight(feature='[8] noting', weight=-0.18960059290047412, std=None, value=1.0), FeatureWeight(feature='[9] the', weight=-0.10566631416930287, std=None, value=1.0), FeatureWeight(feature='[20] African', weight=-0.06259368994207322, std=None, value=1.0), FeatureWeight(feature='[12] promoted', weight=-0.02699920237441571, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.008543813826219014, score=-4.7441257905884395, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('s', [(9, 10)], 0.20787264732896882), ('President', [(11, 20)], -1.380863149361317), ('Obasanjo', [(30, 38)], 0.08014286981955294), ('expressed', [(39, 48)], -0.7717426962334071), ('his', [(49, 52)], 0.0698215184496014), ('noting', [(67, 73)], -0.18960059290047412), ('the', [(74, 77)], -0.10566631416930287), ('promoted', [(91, 99)], -0.02699920237441571), ('African', [(146, 153)], -0.06259368994207322)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature='<BIAS>', weight=-2.564497181205572, std=None, value=1.0), FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-2.179628609382867, std=None, value=None)], pos_remaining=0, neg_remaining=0)), heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q7LAucxcw3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}